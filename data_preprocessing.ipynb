{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6704\\2374804111.py:1: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv('favorita-grocery-sales-forecasting/train.csv/train.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id        date  store_nbr  item_nbr  unit_sales onpromotion\n",
      "0   0  2013-01-01         25    103665         7.0         NaN\n",
      "1   1  2013-01-01         25    105574         1.0         NaN\n",
      "2   2  2013-01-01         25    105575         2.0         NaN\n",
      "3   3  2013-01-01         25    108079         1.0         NaN\n",
      "4   4  2013-01-01         25    108701         1.0         NaN\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('favorita-grocery-sales-forecasting/train.csv/train.csv')\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'favorita-grocery-sales-forecasting/test.csv/test.csv'\n",
    "transactions_path = 'favorita-grocery-sales-forecasting/transactions.csv/transactions.csv'\n",
    "holidays_path = 'favorita-grocery-sales-forecasting/holidays_events.csv/holidays_events.csv'\n",
    "items_path = 'favorita-grocery-sales-forecasting/items.csv/items.csv'\n",
    "oil_path = 'favorita-grocery-sales-forecasting/oil.csv/oil.csv'\n",
    "stores_path = 'favorita-grocery-sales-forecasting/stores.csv/stores.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "test = pd.read_csv(test_path)\n",
    "transactions = pd.read_csv(transactions_path)\n",
    "holidays = pd.read_csv(holidays_path)\n",
    "items = pd.read_csv(items_path)\n",
    "oil = pd.read_csv(oil_path)\n",
    "stores = pd.read_csv(stores_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (125497040, 6)\n",
      "Test: (3370464, 5)\n",
      "Transactions: (83488, 3)\n",
      "Holidays: (350, 6)\n",
      "Items: (4100, 4)\n",
      "Oil: (1218, 2)\n",
      "Stores: (54, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", train.shape)\n",
    "print(\"Test:\", test.shape)\n",
    "print(\"Transactions:\", transactions.shape)\n",
    "print(\"Holidays:\", holidays.shape)\n",
    "print(\"Items:\", items.shape)\n",
    "print(\"Oil:\", oil.shape)\n",
    "print(\"Stores:\", stores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime\n",
    "train['date'] = pd.to_datetime(train['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125497040 entries, 0 to 125497039\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   id           int64         \n",
      " 1   date         datetime64[ns]\n",
      " 2   store_nbr    int64         \n",
      " 3   item_nbr     int64         \n",
      " 4   unit_sales   float64       \n",
      " 5   onpromotion  object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(1)\n",
      "memory usage: 5.6+ GB\n",
      "None\n",
      "   id       date  store_nbr  item_nbr  unit_sales onpromotion\n",
      "0   0 2013-01-01         25    103665         7.0         NaN\n",
      "1   1 2013-01-01         25    105574         1.0         NaN\n",
      "2   2 2013-01-01         25    105575         2.0         NaN\n",
      "3   3 2013-01-01         25    108079         1.0         NaN\n",
      "4   4 2013-01-01         25    108701         1.0         NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data Info:\")\n",
    "print(train.info())\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in onpromotion: [nan False True]\n"
     ]
    }
   ],
   "source": [
    "unique_values = train['onpromotion'].unique()\n",
    "print(\"Unique values in onpromotion:\", unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of onpromotion values:\n",
      "False    96028767\n",
      "True      7810622\n",
      "Name: onpromotion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "promotion_counts = train['onpromotion'].value_counts()\n",
    "print(\"Counts of onpromotion values:\")\n",
    "print(promotion_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125497040 entries, 0 to 125497039\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   id           int64         \n",
      " 1   date         datetime64[ns]\n",
      " 2   store_nbr    int64         \n",
      " 3   item_nbr     int64         \n",
      " 4   unit_sales   float64       \n",
      " 5   onpromotion  bool          \n",
      "dtypes: bool(1), datetime64[ns](1), float64(1), int64(3)\n",
      "memory usage: 4.8 GB\n"
     ]
    }
   ],
   "source": [
    "train['onpromotion'] = train['onpromotion'].fillna(False).astype('bool')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Statistics:\n",
      " count    1.254970e+08\n",
      "mean     8.554865e+00\n",
      "std      2.360515e+01\n",
      "min     -1.537200e+04\n",
      "25%      2.000000e+00\n",
      "50%      4.000000e+00\n",
      "75%      9.000000e+00\n",
      "max      8.944000e+04\n",
      "Name: unit_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Basic describe\n",
    "print(\"Basic Statistics:\\n\", train['unit_sales'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR method for positive sales\n",
    "q1 = train['unit_sales'].quantile(0.25)\n",
    "q3 = train['unit_sales'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    " \n",
    "# Identify outliers\n",
    "outliers = train[(train['unit_sales'] < lower_bound) | (train['unit_sales'] > upper_bound)]\n",
    "\n",
    "# Count of negative sales\n",
    "negative_sales = train[train['unit_sales'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of outliers: 11,497,596\n",
      "Number of negative unit_sales: 7,795\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nNumber of outliers: {len(outliers):,}\")\n",
    "print(f\"Number of negative unit_sales: {len(negative_sales):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame shape: (113992814, 6)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 113992814 entries, 0 to 125497039\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   id           int64         \n",
      " 1   date         datetime64[ns]\n",
      " 2   store_nbr    int64         \n",
      " 3   item_nbr     int64         \n",
      " 4   unit_sales   float64       \n",
      " 5   onpromotion  bool          \n",
      "dtypes: bool(1), datetime64[ns](1), float64(1), int64(3)\n",
      "memory usage: 5.2 GB\n"
     ]
    }
   ],
   "source": [
    "# Remove negative unit_sales\n",
    "train_cleaned = train[train['unit_sales'] >= 0]\n",
    " \n",
    "# Remove outliers based on IQR\n",
    "train_cleaned = train_cleaned[(train_cleaned['unit_sales'] >= lower_bound) &\n",
    "                              (train_cleaned['unit_sales'] <= upper_bound)]\n",
    " \n",
    "print(f\"Cleaned DataFrame shape: {train_cleaned.shape}\")\n",
    "train_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure key columns have proper types\n",
    "stores['store_nbr'] = stores['store_nbr'].astype(int)\n",
    "items['item_nbr'] = items['item_nbr'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stores Data:\n",
      "   store_nbr           city                           state type  cluster\n",
      "0          1          Quito                       Pichincha    D       13\n",
      "1          2          Quito                       Pichincha    D       13\n",
      "2          3          Quito                       Pichincha    D        8\n",
      "3          4          Quito                       Pichincha    D        9\n",
      "4          5  Santo Domingo  Santo Domingo de los Tsachilas    D        4\n",
      "\n",
      "Items Data:\n",
      "   item_nbr        family  class  perishable\n",
      "0     96995     GROCERY I   1093           0\n",
      "1     99197     GROCERY I   1067           0\n",
      "2    103501      CLEANING   3008           0\n",
      "3    103520     GROCERY I   1028           0\n",
      "4    103665  BREAD/BAKERY   2712           1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStores Data:\")\n",
    "print(stores.head())\n",
    "print(\"\\nItems Data:\")\n",
    "print(items.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Merging Stores and Items:\n",
      "       id       date  store_nbr  item_nbr  unit_sales  onpromotion     city  \\\n",
      "0       0 2013-01-01         25    103665         7.0        False  Salinas   \n",
      "1   19811 2013-01-02         25    103665         5.0        False  Salinas   \n",
      "2  100696 2013-01-04         25    103665         5.0        False  Salinas   \n",
      "3  141831 2013-01-05         25    103665         5.0        False  Salinas   \n",
      "4  183815 2013-01-06         25    103665         7.0        False  Salinas   \n",
      "\n",
      "         state type  cluster        family  class  perishable  \n",
      "0  Santa Elena    D        1  BREAD/BAKERY   2712           1  \n",
      "1  Santa Elena    D        1  BREAD/BAKERY   2712           1  \n",
      "2  Santa Elena    D        1  BREAD/BAKERY   2712           1  \n",
      "3  Santa Elena    D        1  BREAD/BAKERY   2712           1  \n",
      "4  Santa Elena    D        1  BREAD/BAKERY   2712           1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 113992814 entries, 0 to 113992813\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   id           int64         \n",
      " 1   date         datetime64[ns]\n",
      " 2   store_nbr    int64         \n",
      " 3   item_nbr     int64         \n",
      " 4   unit_sales   float64       \n",
      " 5   onpromotion  bool          \n",
      " 6   city         object        \n",
      " 7   state        object        \n",
      " 8   type         object        \n",
      " 9   cluster      int64         \n",
      " 10  family       object        \n",
      " 11  class        int64         \n",
      " 12  perishable   int64         \n",
      "dtypes: bool(1), datetime64[ns](1), float64(1), int64(6), object(4)\n",
      "memory usage: 11.1+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge store information on 'store_nbr'\n",
    "merged_df = train.merge(stores, on='store_nbr', how='inner')\n",
    "# Merge item information on 'item_nbr'\n",
    "merged_df = merged_df.merge(items, on='item_nbr', how='inner')\n",
    "print(\"\\nAfter Merging Stores and Items:\")\n",
    "print(merged_df.head())\n",
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Computing and Merging Average Unit Sales:\n",
      "   item_nbr  avg_unit_sales\n",
      "0    103665        4.254618\n",
      "1    103665        4.254618\n",
      "2    103665        4.254618\n",
      "3    103665        4.254618\n",
      "4    103665        4.254618\n"
     ]
    }
   ],
   "source": [
    "# Compute average unit sales per item (or use groupby(['store_nbr','item_nbr']) for a more granular metric)\n",
    "avg_sales = merged_df.groupby('item_nbr')['unit_sales'].mean().reset_index()\n",
    "avg_sales.rename(columns={'unit_sales': 'avg_unit_sales'}, inplace=True)\n",
    "# Merge avg_unit_sales back into the main DataFrame\n",
    "merged_df = merged_df.merge(avg_sales, on='item_nbr', how='inner')\n",
    "print(\"\\nAfter Computing and Merging Average Unit Sales:\")\n",
    "print(merged_df[['item_nbr', 'avg_unit_sales']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Dataset Preview:\n",
      "       id       date  store_nbr  item_nbr  unit_sales  onpromotion     city  \\\n",
      "0       0 2013-01-01         25    103665         7.0        False  Salinas   \n",
      "1   19811 2013-01-02         25    103665         5.0        False  Salinas   \n",
      "2  100696 2013-01-04         25    103665         5.0        False  Salinas   \n",
      "3  141831 2013-01-05         25    103665         5.0        False  Salinas   \n",
      "4  183815 2013-01-06         25    103665         7.0        False  Salinas   \n",
      "\n",
      "         state type  cluster        family  class  perishable  avg_unit_sales  \n",
      "0  Santa Elena    D        1  BREAD/BAKERY   2712           1        4.254618  \n",
      "1  Santa Elena    D        1  BREAD/BAKERY   2712           1        4.254618  \n",
      "2  Santa Elena    D        1  BREAD/BAKERY   2712           1        4.254618  \n",
      "3  Santa Elena    D        1  BREAD/BAKERY   2712           1        4.254618  \n",
      "4  Santa Elena    D        1  BREAD/BAKERY   2712           1        4.254618  \n"
     ]
    }
   ],
   "source": [
    "# Select only the required columns\n",
    "final_columns = [\n",
    "    'id', 'date', 'store_nbr', 'item_nbr', 'unit_sales', 'onpromotion',\n",
    "    'city', 'state', 'type', 'cluster', 'family', 'class', 'perishable',\n",
    "    'avg_unit_sales'\n",
    "]\n",
    "final_dataset = merged_df[final_columns]\n",
    "print(\"\\nFinal Dataset Preview:\")\n",
    "print(final_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the Final Dataset as CSV\n",
    "# final_csv_path = '/content/drive/My Drive/YourFolderName/final_train_dataset1.csv'\n",
    "# final_dataset.to_csv(final_csv_path, index=False)\n",
    "# print(\"\\n✅ Final training dataset saved to:\", final_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage by column:\n",
      "Index              432506336\n",
      "id                 432506336\n",
      "date               432506336\n",
      "store_nbr          432506336\n",
      "item_nbr           432506336\n",
      "unit_sales         432506336\n",
      "onpromotion         54063292\n",
      "city              3442851049\n",
      "state             3565259079\n",
      "type              3135670936\n",
      "cluster            432506336\n",
      "family            3553130020\n",
      "class              432506336\n",
      "perishable         432506336\n",
      "avg_unit_sales     432506336\n",
      "dtype: int64\n",
      "\n",
      "Total memory usage: 17238.65 MB\n",
      "\n",
      "Filtered records: 54063292 rows, 14 columns\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Make sure 'date' is datetime\n",
    "final_dataset['date'] = pd.to_datetime(final_dataset['date'])\n",
    " \n",
    "# Step 2: Filter records from 2015 onwards\n",
    "filtered_df = final_dataset[final_dataset['date'] >= '2016-01-01']\n",
    " \n",
    "# Step 3: Show memory usage summary\n",
    "memory_usage = filtered_df.memory_usage(deep=True)\n",
    "total_memory_mb = memory_usage.sum() / (1024 ** 2)\n",
    " \n",
    "# Step 4: Print memory details\n",
    "print(\"Memory usage by column:\")\n",
    "print(memory_usage)\n",
    " \n",
    "print(f\"\\nTotal memory usage: {total_memory_mb:.2f} MB\")\n",
    " \n",
    "# Optional: Show shape to confirm size\n",
    "print(f\"\\nFiltered records: {filtered_df.shape[0]} rows, {filtered_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id       date  unit_sales  onpromotion     city        state type  \\\n",
      "0  66894873 2016-01-06         2.0        False  Salinas  Santa Elena    D   \n",
      "1  67077674 2016-01-08         4.0        False  Salinas  Santa Elena    D   \n",
      "2  67173081 2016-01-09         6.0        False  Salinas  Santa Elena    D   \n",
      "3  67549594 2016-01-13         1.0        False  Salinas  Santa Elena    D   \n",
      "4  67638605 2016-01-14         2.0        False  Salinas  Santa Elena    D   \n",
      "\n",
      "   cluster        family  class  perishable  avg_unit_sales  \n",
      "0        1  BREAD/BAKERY   2712           1        4.254618  \n",
      "1        1  BREAD/BAKERY   2712           1        4.254618  \n",
      "2        1  BREAD/BAKERY   2712           1        4.254618  \n",
      "3        1  BREAD/BAKERY   2712           1        4.254618  \n",
      "4        1  BREAD/BAKERY   2712           1        4.254618  \n"
     ]
    }
   ],
   "source": [
    "filtered_df = filtered_df.drop(columns=['store_nbr', 'item_nbr'])\n",
    "\n",
    "# Keep only the records where the 'id' column has non-null values.\n",
    "filtered_df = filtered_df[filtered_df['id'].notnull()]\n",
    "\n",
    "# Optionally, reset the index after filtering.\n",
    "final_dataset = filtered_df.reset_index(drop=True)\n",
    "\n",
    "# To check the result:\n",
    "print(final_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage by column:\n",
      "Index                    128\n",
      "id                 432506336\n",
      "date               432506336\n",
      "unit_sales         432506336\n",
      "onpromotion         54063292\n",
      "city              3442851049\n",
      "state             3565259079\n",
      "type              3135670936\n",
      "cluster            432506336\n",
      "family            3553130020\n",
      "class              432506336\n",
      "perishable         432506336\n",
      "avg_unit_sales     432506336\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "memory_usage = final_dataset.memory_usage(deep=True)\n",
    "total_memory_mb = memory_usage.sum() / (1024 ** 2)\n",
    " \n",
    "# Step 4: Print memory details\n",
    "print(\"Memory usage by column:\")\n",
    "print(memory_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total memory usage: 16001.24 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTotal memory usage: {total_memory_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54063292 entries, 0 to 54063291\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   id              int64         \n",
      " 1   date            datetime64[ns]\n",
      " 2   unit_sales      float64       \n",
      " 3   onpromotion     bool          \n",
      " 4   city            object        \n",
      " 5   state           object        \n",
      " 6   type            object        \n",
      " 7   cluster         int64         \n",
      " 8   family          object        \n",
      " 9   class           int64         \n",
      " 10  perishable      int64         \n",
      " 11  avg_unit_sales  float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(2), int64(4), object(4)\n",
      "memory usage: 4.5+ GB\n"
     ]
    }
   ],
   "source": [
    "final_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the Final Dataset as CSV\n",
    "final_dataset.to_csv('final_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
